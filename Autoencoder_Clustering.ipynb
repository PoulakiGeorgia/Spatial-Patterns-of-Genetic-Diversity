{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "The Autoencoder model is developed using keras library. The Artificial Neural Network is constructed to train and validate the one-hot encoded data before the clustering implementation."
      ],
      "metadata": {
        "id": "kokr-XPHkxfb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Autoencoder model:"
      ],
      "metadata": {
        "id": "6LYovte6lIyD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GIRxe5FgkmmP"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import keras\n",
        "from keras import layers, regularizers\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# Convert DataFrame to NumPy array\n",
        "X = final_df.values  # Ensure final_df contains only numeric values\n",
        "\n",
        "# Normalization of the entire dataset\n",
        "scaler = StandardScaler()\n",
        "X_normalized = scaler.fit_transform(X)\n",
        "\n",
        "# Train-Test Split (80% train, 20% test)\n",
        "X_train, X_test = train_test_split(X_normalized, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build Autoencoder\n",
        "input_dim = X_normalized.shape[1]  # Number of features\n",
        "\n",
        "# Input layer\n",
        "input_data = keras.Input(shape=(input_dim,))\n",
        "\n",
        "# Encoder\n",
        "encoded = layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01))(input_data)\n",
        "encoded = layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.01))(encoded)\n",
        "encoded = layers.Dense(16, activation='relu', kernel_regularizer=regularizers.l2(0.01))(encoded)\n",
        "\n",
        "\n",
        "# Decoder\n",
        "decoded = layers.Dense(16, activation='relu')(encoded)\n",
        "decoded = layers.Dense(32, activation='relu')(decoded)\n",
        "decoded = layers.Dense(input_dim, activation='linear')(decoded)\n",
        "\n",
        "# Compile Autoencoder\n",
        "autoencoder = keras.Model(input_data, decoded)\n",
        "autoencoder.compile(optimizer=Adam(learning_rate=0.0005), loss='mean_squared_error')\n",
        "\n",
        "# EarlyStopping to prevent overfitting\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
        "\n",
        "# Train the Autoencoder\n",
        "history = autoencoder.fit(\n",
        "    X_train, X_train,\n",
        "    epochs=200,\n",
        "    batch_size=128,\n",
        "    shuffle=True,\n",
        "    validation_data=(X_test, X_test),\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Plot Training & Validation Loss\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training & Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Evaluate on Test Set\n",
        "test_loss = autoencoder.evaluate(X_test, X_test)\n",
        "print(f\"Test Reconstruction Loss: {test_loss:.4f}\")\n",
        "\n",
        "# Extract Encoded Representations for Clustering\n",
        "encoder = keras.Model(input_data, encoded)\n",
        "X_encoded = encoder.predict(X_normalized)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Elbow method to determine the optimal number of clusters (k) for K-means Clustering."
      ],
      "metadata": {
        "id": "roMIPhHIlPkM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Elbow Method to Find Optimal k\n",
        "inertia_values = []\n",
        "k_values = range(1, 11)  # Test k from 1 to 10\n",
        "\n",
        "for k in k_values:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "    kmeans.fit(X_encoded)  # Use the encoded data for clustering\n",
        "    inertia_values.append(kmeans.inertia_)  # Inertia: sum of squared distances to centroids\n",
        "\n",
        "# Plot Elbow Method\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(k_values, inertia_values, marker='o')\n",
        "plt.xlabel('Number of Clusters (k)')\n",
        "plt.ylabel('Inertia')\n",
        "plt.title('Elbow Method for Optimal k')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "obfpKbKdlYq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "K-means Clustering:"
      ],
      "metadata": {
        "id": "gj6hcSYXlvsK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_clusters = 3  # Number of clusters based on the Elbow Method\n",
        "\n",
        "# Perform K-means clustering on the latent representations (X_encoded)\n",
        "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "clusters_labels = kmeans.fit_predict(X_encoded)  # X_encoded for clustering\n",
        "\n",
        "# Add cluster labels to a DataFrame\n",
        "clustered_data = pd.DataFrame(X_encoded)\n",
        "clustered_data['Cluster'] = clusters_labels  # Add cluster labels as a new column\n",
        "\n",
        "# Visualization using 1st and 2nd dimensions of X_encoded data\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.scatter(X_encoded[:, 0], X_encoded[:, 1], c=clusters_labels, cmap='viridis')\n",
        "plt.xlabel('Latent Dimension 1')\n",
        "plt.ylabel('Latent Dimension 2')\n",
        "plt.title('K-means Clustering on Latent Space')\n",
        "plt.colorbar(label='Cluster')\n",
        "\n",
        "# Save image\n",
        "image4_path = '/content/drive/MyDrive/k-means.png'\n",
        "plt.savefig(image4_path, dpi=300, bbox_inches='tight')  # Save the plot as an image\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Evaluation of Clustering - Silhouette Score\n",
        "from sklearn.metrics import silhouette_score, silhouette_samples\n",
        "\n",
        "# Calculate Silhouette Score\n",
        "silhouette_avg = silhouette_score(X_encoded, clusters_labels)\n",
        "print(f\"Silhouette Score for {n_clusters} clusters: {silhouette_avg:.2f}\")\n",
        "\n",
        "# Evaluation for each cluster\n",
        "silhouette_values = silhouette_samples(X_encoded, clusters_labels)\n",
        "for i in range(n_clusters):\n",
        "    cluster_silhouette_avg = silhouette_values[clusters_labels == i].mean()\n",
        "    print(f\"Cluster {i}: Silhouette Score = {cluster_silhouette_avg:.2f}\")"
      ],
      "metadata": {
        "id": "rLpdszyblco4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hierarchical Clustering:"
      ],
      "metadata": {
        "id": "oKtrzsoylqbK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load libraries\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "\n",
        "\n",
        "# Convert panda series to list\n",
        "location_labels = location_data.tolist()\n",
        "\n",
        "\n",
        "unique_locations = list(set(location_labels))  # Get unique locations\n",
        "location_colors = {region: plt.cm.tab10(i) for i, region in enumerate(unique_locations)}  # Create color dictionary for each location\n",
        "\n",
        "# Assign color to each location label\n",
        "def assign_colors(location_labels, location_colors):\n",
        "    leaf_colors = []\n",
        "    for label in location_labels:\n",
        "        location = label\n",
        "        color = location_colors[location]\n",
        "        leaf_colors.append(color)\n",
        "    return leaf_colors\n",
        "\n",
        "\n",
        "# Perform Hierarchical Clustering on Latent Representations\n",
        "linked = linkage(X_encoded, method='ward')  # Ward's method minimizes variance\n",
        "\n",
        "# Dendrogram\n",
        "cutoff = 6\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "dendrogram(linked,\n",
        "           orientation='top',\n",
        "           color_threshold=cutoff,\n",
        "           above_threshold_color='grey',\n",
        "           labels=location_labels,\n",
        "           leaf_rotation=90,\n",
        "           leaf_font_size= 8)\n",
        "\n",
        "# Get x-axis\n",
        "ax = plt.gca()\n",
        "x_labels = ax.get_xticklabels()  # Retrieve x-axis labels\n",
        "# Iterate through the x labels and change their colors if they match a region\n",
        "for label in x_labels:\n",
        "    text = label.get_text()\n",
        "    if text in location_colors:\n",
        "        label.set_color(location_colors[text])\n",
        "\n",
        "plt.title(\"Hierarchical Clustering Dendrogram\")\n",
        "plt.xlabel(\"Samples\")\n",
        "plt.ylabel(\"Distance\")\n",
        "plt.axhline(y=6, color='r', linestyle='--')\n",
        "\n",
        "# Save image\n",
        "image5_path = '/content/drive/MyDrive/dendrogram_ward.png'\n",
        "plt.savefig(image5_path, dpi=300, bbox_inches='tight')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TFcBw-P-lgW6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}